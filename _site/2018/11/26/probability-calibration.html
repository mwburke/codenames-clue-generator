<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Probablity Calibration - Works of Chart</title>
    <meta name="author"  content="Matthew Burke">
    <meta name="description" content="Probablity Calibration">
    <meta name="keywords"  content="probability, ml">
    <!-- Open Graph -->
    <meta property="og:title" content="Probablity Calibration - Works of Chart">
    <meta property="og:type" content="website">
    <meta property="og:url" content="http://worksofchart.com/2018/11/26/probability-calibration.html">
    <meta property="og:description" content="Making sense of data">
    <meta property="og:site_name" content="Works of Chart">
    <link rel="stylesheet" href="//cdn.staticfile.org/normalize/6.0.0/normalize.min.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_roc50gemkxpw4s4i.css">
    <link rel="stylesheet" href="/assets/css/github-markdown.css">
    <link rel="stylesheet" href="/assets/css/prism.css">
    <link rel="stylesheet" href="/assets/css/share.min.css">
    <link rel="stylesheet" href="/assets/css/app.min.css">
    
    <!--
Author: Ray-Eldath
refer to:
 - http://docs.mathjax.org/en/latest/options/index.html
-->

	<script type="text/javascript" async src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
	
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
		jax: ["input/TeX", "output/HTML-CSS"],
		tex2jax: {
			inlineMath: [ ["$", "$"] ],
			displayMath: [ ["$$", "$$"] ],
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
		},
		"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
      });
    </script>

    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-112640723-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-112640723-1');
    </script>

</head>

<body>
    <!--[if lt IE 10]>
<div class="alert-danger" role="alert">你的浏览器实在太太太旧了，放学别走，升级完浏览器再说！<a target="_blank" class="alert-link" href="http://browsehappy.com">立即升级</a></div>
<![endif]-->
<input id="nm-switch" type="hidden" value="false">

<header class="g-header">
    <div class="g-logo">
      <a href="/"></a>
    </div>
    <i id="menu-toggle" class="iconfont icon-menu"></i>
    <nav class="g-nav">
        <ul>
            
            <li><a href="/">home</a></li>
            
            <li><a href="/tags.html">tags</a></li>
            
            <li><a href="/about.html">about</a></li>
            
        </ul>
    </nav>
</header>


<header class="g-banner post-header post-pattern-circuitBoard bgcolor-default " data-theme="default">
    <div class="post-wrapper">
        <div class="post-tags">
            
            
            <a href="http://worksofchart.com/tags#probability" class="post-tag">probability</a>
            
            <a href="http://worksofchart.com/tags#ml" class="post-tag">ml</a>
            
            
        </div>
        <h1>Probablity Calibration</h1>
        <div class="post-meta">
            <span class="post-meta-item"><i class="iconfont icon-author"></i><a href="http://worksofchart.com" target="_blank" rel="author">Matthew</a></></span>
            <time class="post-meta-item" datetime="18-11-26"><i class="iconfont icon-date"></i>26 Nov 2018</time>
        </div>
    </div>
    
    <div class="filter"></div>
    <div class="post-cover" style="background: url('/assets/img/calibration_curve_2.png') center no-repeat; background-size: cover;">
    
</header>

<div class="post-content">
    
    <h2 class="post-subtitle">Predictions As Actual Probabilities</h2>
    
    <article class="markdown-body">
        <h2 id="predictions-as-confidence">Predictions As Confidence</h2>

<p>As you may already know, classification problems in machine learning commonly (though not always) use algorithms that output a <em>predicted probability</em> value that can be used to gauge confidence in how sure your model is that the input belongs to one particular class.</p>

<h2 id="setting-probability-thresholds">Setting Probability Thresholds</h2>

<p>In introductory ML courses, a default value of 0.50 is usually used as the prediction cutoff for making the decision to consider a binary classification output as either positive or negative class, but in industry, selecting the right cutoff threshold is critical to making good business decisions.</p>

<p>If the cost associated with false negatives is large, it may be optimal to use a lower probability decision threshold to capture more positive users at the expense of including more false positives, and vice versa, and the data scientist will work with the business units to balance this tradeoff in order to minimize cost or maximize the benefit. Ultimately, this causes the predictions to act more as a ranking system for applications that require binary classifications as the final output than actually leveraging the values themselves.</p>

<h2 id="interpretation-problems">Interpretation Problems</h2>

<h3 id="model-as-ranking">Model As Ranking</h3>

<p>This model-as-ranking system works fine in many situations, but what happens when your predicted probability does not actually represent the probability and the business unit consuming your predictions assumes that they are? An example of this might be the likelihood of conversion for a given user, which is then multiplied by potential LTV to prioritize leads for a sales organization based on expected ROI. If a model tends to over/underestimate probabilities at the lower/upper ends of the predicted probability spectrum respctively (as random forest models have been known to do), you can end up spending effort on individuals who are less worth the team’s time, wasting resources and potentially losing revenue.</p>

<p>Scikit-learn has a great overview on some common algorithms that result in biased predicted probabilities. I’ve taken the liberty of displaying the chart from that overview here. Visit <a href="https://scikit-learn.org/stable/auto_examples/calibration/plot_compare_calibration.html">this link</a> to get the full code used to generate the plot or just look at the documentation for the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.calibration.calibration_curve.html">sklearn.calibration.calibration_curve</a> function</p>

<p><img src="/assets/img/calibration_curve_1.png" alt="https://scikit-learn.org/stable/auto_examples/calibration/plot_compare_calibration.html" /></p>

<h3 id="parallel-model-consumption">Parallel Model Consumption</h3>

<p>Additionally, models can be used in conjunction with one another to provide targets in context. Going back to our expected LTV example, a business may have separate conversion likelihood models for different segments of their customer population, with every user being assigned a conversion probability from a single model. If not all models produce well-calibrated predicted probabilities, one could end up dominating the others while still having good metrics when considered individually.</p>

<h4 id="auroc-may-be-misleading">AUROC May Be Misleading</h4>

<p>One common performance metric that is used to measure the effectiveness of the model across the range of predicted probabilities is the area under the receiving operating characteristic (ROC) curve. In case you aren’t familiar with the ROC curve, it is a plot of the model’s true positive rate vs the false positive rate as the probability is varied from 0 to 1, and as such, it is considered more of a robust metric than accuracy alone in cases where classes are imbalanced or the cost of true/false positives are unknown as of yet.</p>

<p>While it is a good metric, it is <strong>not</strong> sensitive to the absolute value of the predicted probabilities, only the performance at every probability point. If all of the predicted probabilities are multiplied by a constant, the value of the AUROC does not change, which may mislead the modeler into believing their probabilities are good to use, while in fact, they are consistently over/underestimating the results.</p>

<p>For example, the three predicted probability density distributions below are just scaled versions of the output from the same model. Their distributions are obviously very different from one another, but because they are scaled by a constant, they all have an equivalent AUROC score.</p>

<p><img src="/assets/img/pred_probs_scaled.png" alt="" /></p>

<h3 id="sampling-bias">Sampling Bias</h3>

<p>Many problems have imbalanced datasets in terms of the target variable with a significant portion of the records belonging to one class. Various techniques have been developed to counteract these problem, including oversampling the minority class, downsampling the majority class and generating synthetic samples from the minority class to closer achieve class number parity. However, these techniques can result in increased AUROC scores while biasing the predicted probabilities to be less calibrated to actual.</p>

<p>Here is an example of how a generally well calibrated classifier (Logistic Regression) can be biased depending upon the ratio of the positive to negative class in the training dataset:</p>

<p><img src="/assets/img/calibration_curve_2.png" alt="" /></p>

<h3 id="solution-brier-score">Solution: Brier Score</h3>

<p>The <a href="https://en.wikipedia.org/wiki/Brier_score">brier score</a> “can be thought of as… a measure of the ‘calibration’ of a set of probabilistic predictions” according to Wikipedia, and essentially is the average squared difference between the probability that was forecast and the actual outcome of the event. This makes its interpretation analogous to the root mean squared error for regression problems, and does take into account the scale of the predictions.</p>

<p>For example, here is the table of the AUROC as well as the Brier scores for the calibration curves above. You can clearly see that different models may have the same AUROC scores while having significantly different brier scores due to the various techniques.</p>

<table>
  <thead>
    <tr>
      <th>Ratio</th>
      <th>AUROC</th>
      <th>Brier Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0.5</td>
      <td>0.895</td>
      <td>0.166</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.895</td>
      <td>0.131</td>
    </tr>
    <tr>
      <td>1.25</td>
      <td>0.895</td>
      <td>0.125</td>
    </tr>
    <tr>
      <td>1.5</td>
      <td>0.895</td>
      <td>0.121</td>
    </tr>
  </tbody>
</table>

<p>While this isn’t the only solution to this problem, it’s a quick way to sanity check your solutions and signal the need for additional inspection to make sure that your predictions are consistently calibrated and giving you the values you are expecting.</p>

<h3 id="further-research">Further Research</h3>

<p>Scikit-learn has implemented the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html">CalibratedClassifierCV</a> class to adjust your classifiers to be more calibrated either during training, or to adjust the predictions by calibrating the classifier post-training.</p>

    </article>
    
</div>

<section class="author-detail">
    <section class="post-footer-item author-card">
        <div class="avatar">
            <img src="http://worksofchart.com/assets/img/other-profile.jpg" alt="">
        </div>
        <div class="author-name" rel="author">Matthew Burke</div>
        <div class="bio">
            <p>Data Visualization, Machine Learning, Optimization</p>
        </div>
        
        <ul class="sns-links">
            
            <li>
                <a href="//twitter.com/mattburkeley" target="_blank">
                    <i class="iconfont icon-twitter"></i>
                </a>
            </li>
            
            <li>
                <a href="//www.linkedin.com/in/matthew-burke-data-science" target="_blank">
                    <i class="iconfont icon-linkedin"></i>
                </a>
            </li>
            
            <li>
                <a href="//github.com/mwburke" target="_blank">
                    <i class="iconfont icon-github"></i>
                </a>
            </li>
            
        </ul>
        
    </section>
    <section class="post-footer-item read-next">
        
        <div class="read-next-item">
            <a href="/2018/12/04/idyll-pumpkin-taste-test.html" class="read-next-link"></a>
            <section>
                <span>Introduction to Idyll</span>
                <p>Over Thanksgiving, some friends of mine set out to find t...</p>
            </section>
            
            <div class="filter"></div>
            <img src="/assets/img/idyll_intro_votes.png" alt="">
            
        </div>
        
        
        <div class="read-next-item">
            <a href="/2018/08/24/quantile-regression.html" class="read-next-link"></a>
            <section>
                <span>Quantile Regression</span>
                <p>Black Box Machine LearningThe trend in machine learning t...</p>
            </section>
            
            <div class="filter"></div>
            <img src="/assets/img/quantile_slope_values.png" alt="">
            
        </div>
        
    </section>
    
</section>

<footer class="g-footer">
    <section>Works of Chart © 2018</section>
    <section>Powered by <a href="//jekyllrb.com">Jekyll</a> | <a href="https://github.com/kaeyleo/jekyll-theme-H2O">Theme H2O</a></section>
</footer>

<script src="/assets/js/social-share.min.js"></script>
<script>
    socialShare('.social-share', {
        sites: ['twitter','linkedin','github'],
        wechatQrcodeTitle: "分享到微信朋友圈",
        wechatQrcodeHelper: '<p>扫码后点击右上角</p><p>将本文分享至朋友圈</p>'
    });
</script>
<script>
/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
/*写入自己的disqus信息*/
s.src = 'https://mwburke.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<script src="https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js"></script>
<script src="/assets/js/prism.js"></script>
<script src="/assets/js/index.min.js"></script>
</body>
</html>
